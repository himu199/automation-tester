{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_html_path = \"\"\n",
    "output_csv_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install pandas\n",
    "import re\n",
    "from pandas import pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_number(text):\n",
    "    \"\"\"Remove commas from numbers and convert to integer\"\"\"\n",
    "    return int(text.replace(',', ''))\n",
    "\n",
    "def extract_profiles(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    profiles = []\n",
    "    columns = [\n",
    "        'Onlyfans_name', 'Name', 'Subscribers', 'Likes', 'Photos', 'Videos', 'Price',\n",
    "        'twitter_link','Onlyfans_link' 'instagram_link', 'tiktok_link', 'fansly_link', 'Info'\n",
    "    ]\n",
    "    \n",
    "    # Find all result divs\n",
    "    results = soup.find_all('div', class_='result')\n",
    "    \n",
    "    for result in results:\n",
    "        profile = {}\n",
    "        \n",
    "        # Get Onlyfans_name from img title\n",
    "        img = result.find('img')\n",
    "        if img:\n",
    "            name = img.get('title', '')\n",
    "            profile['Onlyfans_name'] = name\n",
    "            profile['Onlyfans_link'] = f'https://onlyfans.com/{name}'\n",
    "            \n",
    "        # Get Name from h3\n",
    "        h3 = result.find('h3')\n",
    "        if h3:\n",
    "            profile['Name'] = h3.text.strip()\n",
    "            \n",
    "            \n",
    "        # Get Info from about div\n",
    "        about = result.find('div', class_='pb-3 text-muted about')\n",
    "        if about:\n",
    "            profile['Info'] = about.text.strip()\n",
    "            \n",
    "        # Get profile info (likes, photos, videos, price)\n",
    "        profile_info = result.find('div', class_='profile-info')\n",
    "        if profile_info:\n",
    "            # Extract Likes\n",
    "\n",
    "                \n",
    "            # Extract Photos\n",
    "            spans = profile_info.find_all('span', class_='mr-3')\n",
    "            for span in spans:\n",
    "                if 'Photos' in span.get_text():\n",
    "                    profile['Photos'] = clean_number(span.get_text().replace('Photos', '').strip())\n",
    "                if 'Videos' in span.get_text():\n",
    "                    profile['Videos'] = clean_number(span.get_text().replace('Videos', '').strip())\n",
    "                if 'Subscribers' in span.get_text():\n",
    "                    profile['Subscribers'] = clean_number(span.get_text().replace('Subscribers', '').strip())\n",
    "                if 'Likes' in span.get_text():\n",
    "                    profile['Likes'] = clean_number(span.get_text().replace('Likes', '').strip())\n",
    "                \n",
    "            # Extract Price\n",
    "            price_span = profile_info.find('span', class_='')\n",
    "            if price_span:\n",
    "                if price_span.find('svg', {'title': 'free trial link'}):\n",
    "                    profile['Price'] = 'free trial link'\n",
    "                elif price_span.find('strong'):\n",
    "                    profile['Price'] = price_span.find('strong').text.strip()\n",
    "                    \n",
    "        # Get social media links\n",
    "        social_div = result.find('div', class_='float-right profile-social')\n",
    "        if social_div:\n",
    "            social_links = social_div.find_all('a')\n",
    "            for link in social_links:\n",
    "                platform = link.get('title', '').lower()\n",
    "                if platform:\n",
    "                    profile[f'{platform}_link'] = link.get('href', '')\n",
    "                    if f'{platform}_link' not in columns:\n",
    "                        columns.append(f'{platform}_link')\n",
    "                    \n",
    "        profiles.append(profile)\n",
    "        print(f\"Profiles scraped:{len(profiles)}\")\n",
    "    print(columns)    \n",
    "    return profiles\n",
    "\n",
    "with open(input_html_path, 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "profiles = extract_profiles(html_content) \n",
    "columns = ['Onlyfans_name', 'Name', 'Subscribers', 'Likes', 'Photos', \n",
    "           'Videos', 'Price','Onlyfans_link','instagram_link', 'twitter_link',  'tiktok_link',\n",
    "           'fansly_link', 'pornhub_link','patreon_link', 'Info', ]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(profiles, columns=columns)\n",
    "df = df.drop_duplicates(subset=['Onlyfans_name'], keep='first')\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
